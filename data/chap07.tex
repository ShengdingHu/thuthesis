\chapter{总结与展望}

\section{研究工作总结}

语言模型是自然语言处理乃至人工智能的核心研究领域之一，近年来，大语言模型的研究与应用取得了长足进展。大语言模型通过大规模预训练和高质量数据微调获得了极高的通用性和专业性，成为当前迈向通用人工智能的最有潜力的路线。大语言模型的智能提升遵循扩展定律，这表明其性能随训练资源增加而提高。然而，由于人类资源的有限性，这已成为制约大语言模型智能发展的核心瓶颈之一。

当前大语言模型训练已进入百万亿参数时代，其资源消耗呈指数级增长趋势。以OpenAI的GPT-4为例，其训练需要消耗约$10^25$次浮点计算，资金开销在数亿美元级别。扩展定律揭示的性能与模型规模、数据量、计算量的幂律关系，使追求更大规模模型成为必然选择。然而，人类短期内资源总量有限，如何提高资源利用效率已成为当前人工智能领域亟待解决的重要问题。

本文致力于减少大语言模型训练过程中的资源消耗，从而促进模型规模的进一步发展。具体而言，本文研究了大语言模型训练过程中两个主要阶段——预训练阶段和微调阶段——各自面临的资源挑战。对于预训练阶段，不可预测性导致预训练反复调优，进而浪费了大量资源；对于微调阶段，高质量数据消耗量大和微调参数冗余度高导致了微调的资源浪费。因此，本文提出了可预测预训练和低资源微调两个研究目标，并取得了一系列重要进展。

本文的主要研究内容与贡献如下：

\begin{enumerate}

\item \textit{面向可预测预训练的超参数扩展规律与性能扩展定律。} 

本研究首先基于Tensor Program进行探索，在真实场景对tensor program进行了深入研究，发现在辅以批量大小的扩展方案时，可以获得稳定的学习率扩展规律。本研究还对其他结构变体，例如QK-Norm，是否能对超参数稳定起到关键作用进行了研究。 在得到稳定的超参扩展规律带来的损失扩展规律后，本研究深入探索了性能扩展规律。性能扩展定律被认为是非常困难的，因为任务性能不仅影响因素众多，还会表现出波动性和涌现性（即涌现能力）。针对这个问题，本研究进行了深入实验，提出了一种基于大量采样的提升模型评估分辨率的方法，证明了这一方法是真实表现的无偏估计，并且假如计算资源允许，可以精确到任意精度。本研究进一步提出了性能扩展定律，区别于损失扩展定律，该定律可以直接对下游任务性能进行预测。引入了数据集级别扩展和样本级别扩展两种方案，并提出损失辅助预测方法。这些方法将性能预测精度提升到99\%以上，初步解决了性能扩展规律的问题，避免了大规模预训练实验的反复试错，大幅降低了训练资源消耗。

\item \textit{面向可预测预训练的可复用扩展定律与高效退火迭代。} 

本研究分析了进行扩展定律拟合过程中的资源消耗，发现现有文献的拟合方法需要消耗的计算量和调研模型参数规模个数以及调研数据规模个数都成线性关系，因此在数据和模型两个维度的扩展定律研究需要消耗平方复杂度的算力。本研究思考了不同数据量下的模型训练无法复用训练过程的原因，将其归结为学习率调度对损失的影响带来的不可复用性。 本研究分析了当前绝大部分模型训练都使用的学习率调度策略，提炼出其效果优异的原因，即同时具备全局最优解寻找和局部最优解寻找（退火）的特点。本研究提出将占训练过程绝大部分时间的全局最优解进行多模型共享，再通过时机各异的局部最优解寻找来完成模型训练。研究证明，这种方法使数据维度的扩展定律拟合消耗的资源变为常数量级，有效提高了扩展定律拟合过程的高效性。本研究进一步实验指出，基于以上策略的扩展定律拟合方法，由于其可复用的退火阶段，使得高质量数据迭代实验变得非常高效。研究仔细分析了退火过程中引入不同数据对于模型训练结果的影响，发现在退火过程中引入高质量数据能显著提高模型在下游任务上的表现。由于可复用的退火阶段在整个训练过程占比很小，所以可以使用少量的算力进行多次性能迭代。此外，本研究还探索了退火迭代的训练动力学方面的原因，为后人对训练机理的探索提供了新的方向。综合利用上述方法，本研究利用1/7的算力和1/3的模型大小，训练了性能超越Llama2-7B的模型，充分证明了本研究方案的有效性和实用价值。

\item \textit{面向低资源微调的能力激发与知识激活。} 

本研究从微调阶段的数据角度出发，首先研究了预训练模型对于分布外任务是否可以使用少量数据习得。以"错误先验立场"问题为例开展研究，该类问题的特点是回答所需知识存在于大语言模型的预训练阶段，但由于分布差异导致模型无法有效调用这些知识进行回答。本研究首次提供了精标注的人类对于"错误先验立场"问题的回答，证明只需要百到千量级的数据，就可以将模型的回复正确率从随机水平提升到接近90\%的准确率。这一发现提供了"小数据激活大能力"的有力证据，该思路也在后续的Instruction Tuning以及RLHF等工作中得到了进一步验证。本研究进一步探索了对于与预训练模型能力更为接近的分布内任务，例如情感分类和主题分类，是否可以通过更少量的样本或者零样本来进行适配。知识微调是大模型范式下的有效适配手段，其利用模板和表达器来完成模型训练分布到任务输入输出空间的变换。本研究提出了知识提示微调的概念，即在提示微调的基础上，引入知识库扩充的表达器，使得模型在微调过程中可以更好地利用预训练模型的知识。研究表明，通过在提示微调的表达器中引入人类知识先验，能够将模型性能提升高达17\%，大幅降低了所需样本量。

\item \textit{面向低资源微调的参数高效微调模块自动化寻优。} 

本研究从微调阶段的存算资源角度出发，研究了参数高效微调的自动化模块选择功能。传统参数高效微调的方法会选择默认模块进行微调。尽管这种方法能够大幅减少需要微调的参数量，然而由于在预训练过程中，不同模块已经训练出不同的分工，微调时使用默认模块可能会导致模型性能不能充分发挥。本研究提出了一种基于自动化模块选择的参数高效微调框架，该框架建立在对所有参数高效微调方法的统一建模视角下，借鉴了神经架构自动搜索算法，并创新地提出了可训练硬稀疏化优化目标，精准控制可微调参数总量。本研究使参数高效微调所需的微调参数量从全参数的1\%进一步降低到0.01\%量级，大幅减少了存算资源需求。
% 本研究同时提供了一个灵活轻便的参数高效微调代码库，在实现上通过"猴子补丁"的方式灵活修改预训练模型的张量流，使其能够动态加载和移除任意位置的参数高效微调模块，也可以同时加载多个参数高效微调模块，甚至组合不同种类的参数高效微调模块。在用户体验上，本代码库提供了一套完整的参数高效微调模块接口，用户可以通过简单的配置文件，即可实现对预训练模型的参数高效微调，极大地降低了技术门槛。

\end{enumerate}

总结来说，本文对大语言模型训练全流程提出了高效解决方法，这些方法有利于模型进一步进行规模扩展以实现更高的智能上限。本文的主要贡献可以概括为四个方面：(1)提出了超参数扩展规律与性能扩展定律，实现了对下游任务性能的高精度预测；(2)提出了可复用扩展定律与高效退火迭代技术，显著降低了扩展定律拟合的资源消耗；(3)研究了能力激发与知识提示微调方法，以极少样本实现模型能力的有效激活；(4)提出了参数高效微调模块自动化寻优框架，将微调参数量降至全参数的万分之一量级。

与此同时，本文的研究成果对包括模型训练机理、模型参数功能分区、模型涌现能力成因等方面都提供了新的见解。这些创新不仅降低了大模型训练的资源门槛，也为推动人工智能领域的可持续发展做出了重要贡献。

\section{未来工作展望}

大语言模型高效训练研究仍处于高速发展阶段，并且训练方法本身也在同步演进，例如RLHF训练、多模态统一训练。未来可以从以下几个方向继续深入探索：

\begin{enumerate}

\item \textit{大规模强化学习扩展规律和超参数定律。} 

继大规模预训练以后，大规模强化学习将成为下一个主要资源消耗阶段。尽管当前RLHF应用虽已广泛，但其背后的扩展规律仍处于经验探索阶段，缺乏系统性理解。并且以O1、R1为代表的长思维链强化学习技术，尚处于萌芽阶段。未来研究将揭示强化学习中参数规模、训练轮次、奖励信号复杂度与涌现能力间的定量关系，建立类似于监督学习中已有的扩展定律。理解这些规律将使我们能够预测训练资源投入与回报之间的关系，从而做出更合理的资源分配决策。从长远来看，强化学习扩展规律研究将推动理解人类反馈与模型能力提升间的复杂关系，揭示人类价值观如何在大模型中被有效表达和强化。这不仅具有理论价值，也将为解决AI对齐问题提供实证基础，可能成为安全可控AI发展的重要理论支柱。

\item \textit{多模态统一训练扩展规律。} 

多模态统一训练扩展规律研究将致力于揭示跨越视觉、语言、音频等不同感知通道的统一学习机制，同时必须深入探索模态间干扰现象这一核心挑战。当前多模态研究已经观察到"负迁移"现象——模型在整合多模态信息过程中，一种模态的引入有时会损害其他模态的表征质量，使得联合训练性能反而低于单模态训练。这种模态冲突现象尚未纳入现有扩展理论框架，理解其机制将成为未来研究的关键突破点。

\item \textit{硬件感知的预训练优化。} 

未来硬件感知的预训练优化研究将突破当前算法与硬件分离设计的局限，向着全栈协同优化的方向发展。随着专用AI芯片架构日益多元化，预训练算法将不再以通用计算为目标，而是根据底层硬件特性进行根本性重构。这种范式转变意味着算法设计者需要深入理解硬件架构特性，而硬件设计者也需要考虑大模型训练的算法需求，形成一种双向反馈的协同设计思路。相应的，扩展定律也应该考虑到不同超参数在性能和计算效率上的双面影响，综合考虑和设计预训练扩展方案。

\item \textit{大模型训练机理。} 


大模型训练机理研究将从实践中的经验积累转向系统的理论构建，致力于回答“为什么大模型能够有效”、“大模型训练发生了什么”这些根本问题。当前，大模型的许多能力尤其是涌现能力，往往是意外发现而非设计所得，这反映出我们对深度学习本质的理解仍然有限。未来研究将不满足于对现象的描述，而是追求揭示背后的原理。本文所提出的WSD调度揭示，我们对大模型的优化理论理解尚浅，目前尚不存在理论可以定量解释大模型退火阶段下降的损失幅度。在这一方向进一步研究将促进深度学习与其他科学领域如统计学、信息几何学等深度融合，可能形成全新的理论框架。通过对大模型内部表征形成、推理路径的深入分析，研究者将能够构建起描述神经网络规模、优化方案与最终性能之间关系的数学模型，为未来模型设计提供理论指导。

\end{enumerate}